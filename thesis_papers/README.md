# PDDL PLANNING WITH PRE-TRAINED LARGE LANGUAGE MODELS

> `6_pddl_planning_with_pretrained.pdf`

**GPT-made summary**

This paper explores using large language models (LLMs), like OpenAI's Codex, to address PDDL-based AI planning problems. The idea is to leverage LLMs' reasoning capabilities through few-shot prompting to solve planning tasks or guide traditional heuristic-based planners. Results show that while LLMs struggle to independently solve complex problems, they perform well in simpler and novel domains. Moreover, their outputs significantly improve the performance of heuristic planners, demonstrating the potential of hybrid approaches that combine LLMs with traditional planning techniques.

# Attention Is All You Need

> `1706.03762v7.pdf`

**GPT-made summary**

This paper introduces the Transformer model, a novel architecture for sequence transduction that relies entirely on attention mechanisms, eliminating recurrence and convolution. The idea is to use self-attention to capture global dependencies in sequences, enabling greater parallelization and efficiency. Results show state-of-the-art performance in machine translation tasks, with faster training times compared to previous models, and strong generalization to other tasks like English constituency parsing.

# LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers

> `2305.18396v3.pdf`

**GPT-made summary**

This paper proposes a framework to enable private inference for large language models (LLMs) using homomorphic encryption (HE) and secure multi-party computation (MPC). By replacing computationally expensive operators in transformers (e.g., GELU, Softmax, LayerNorm) with privacy-friendly approximations, the approach achieves 5Ã— faster computation and 80% lower communication costs compared to existing methods, with minimal accuracy loss. This demonstrates the feasibility of efficient, privacy-preserving LLM inference.

- `2306.13063v2.pdf`: CAN LLMS EXPRESS THEIR UNCERTAINTY? AN EMPIRICAL EVALUATION OF CONFIDENCE ELICITATION IN LLMS
- `2307.01928v2.pdf`: Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners
- `2307.10236v4.pdf`: Look Before You Leap: An Exploratory Study of Uncertainty Analysis for Large Language Models
- `2311.02017v2.pdf`: DELIVERAI: A DISTRIBUTED PATH-SHARING NETWORK BASED SOLUTION FOR THE LAST MILE FOOD DELIVERY PROBLEM
- `2401.12794v3.pdf`: Benchmarking LLMs via Uncertainty Quantification
- `2406.13094v2.pdf`: EXPLORING AND BENCHMARKING PLANNING CAPABILITIES OF LARGE LANGUAGE MODELS
- `125977151.pdf`: An AI Planning Approach to Emergency Material Scheduling Using Numerical PDDL
- `needle_in_a_haystack_test.pdf`: The Needle In a Haystack Test
